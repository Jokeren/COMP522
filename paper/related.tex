\paragraph{Task pools}
There is a large body of work on lock-free unbounded FIFO queues and LIFO
stacks~\cite{Gidenstam:2010:CLQ:1940234.1940266,Hendler:2004:SLS:1007912.1007944,
Hoffman:2007:BQ:1782394.1782423, Michael:1996:SFP:248052.248106,Moir:2005:UEI:1073970.1074013}.
However, due to the inherent need for ordering all operations, such algorithms
generally have high contention and do not scale, and are therefore less appealing for use as task pools. 

A number of previous works have recognized this limitation, and observed that strict FIFO
order is seldom needed in multi-core systems~\cite{Afek:2010:SPP:1885276.1885295,springerlink:10.1007/978-3-642-17653-1_29,
Basin:2011:CST:2075029.2075087,Sundell:2011:LAC:1989493.1989550}. To the best of our knowledge, all previous 
solutions use strong atomic operations (like CAS), at least in every consume operation. Moreover, most of
them~\cite{Afek:2010:SPP:1885276.1885295,springerlink:10.1007/978-3-642-17653-1_29,
Basin:2011:CST:2075029.2075087} do not partition the pool among processors, and therefore do not achieve
good locality and cache-friendliness, which has been shown to limit their scalability on NUMA systems~\cite{Basin:Thesis:2011}.

The closest non-FIFO pool to our work is the Concurrent Bags of
Sundell et al.~\cite{Sundell:2011:LAC:1989493.1989550}, which, like SALSA, uses 
per-producer chunk lists. 
This work is optimized for the case that the same threads are both consumers and producers, and typically consume from themselves, while SALSA improves the performance of such a task pool in NUMA environments where producers and consumers are separate threads.
Unlike our pool, the Concurrent Bags algorithm uses strong atomic operations
upon each consume. In addition, steals are performed in the granularity of single tasks and
not whole chunks as in SALSA. Overall, their throughput does not scale linearly with the number of participating threads,
as shown in~\cite{Sundell:2011:LAC:1989493.1989550} and in Section~\ref{sec:evaluation} of this paper.

\paragraph{Techniques}
Variations of techniques we employ were previously used in various contexts. 
Work-stealing~\cite{Blumofe:1999:SMC:324133.324234} is a standard way to reduce
contention by using individual per-consumer pools, where tasks may be stolen from one pool to
another. 
We improve the efficiency of stealing by transferring a chunk of tasks upon every steal
operation. Hendler et al.~\cite{Hendler:2002:NSW:571825.571876} have proposed stealing of multiple
items by copying a range of tasks from one dequeue to another, but this approach requires
costly CAS operations on the fast-path and introduces non-negligible overhead for item copying. In
contrast, our approach of chunk-based stealing coincides with our synchronization-free fast-path,
and steals whole chunks in O(1) steps. Furthermore, our use of page-size chunks allows for data
migration in NUMA architectures to improve locality, as done in~\cite{Blagodurov:2011:CNC:2002181.2002182}.

The principle of keeping NUMA-local data structures was previously used 
by Dice et al. for constructing scalable NUMA locks~\cite{Dice:2011:FNL:1989493.1989502}. 
Similarly to their work, our algorithm's data allocation scheme is designed to reduce inter-chip communication. 

The concept of a synchronization-free fast-path previously
appeared in works on scheduling queues,
e.g.,~\cite{Arora:1998:TSM:277651.277678,Hendler:2006:DNW:1160290.1160294}. However, these works
assume that the same process is both the producer and the consumer, and hence the
synchronization-free fast-path is actually used only when a process transfers data to \emph{itself}.
On the other hand, our pool is synchronization-free even when tasks are transfered among multiple
threads; our synchronization-free fast-path is used also when multiple producers produce data for
a single consumer. We do not know of any other work that supports synchronization-free data
transfer among different threads.


The idea of organizing data in chunks to preserve locality in dynamically-sized data
structures was previously used
in~\cite{Braginsky:2011:LLL:1946143.1946153, Gidenstam:2010:CLQ:1940234.1940266,
Hendler:2006:DNW:1160290.1160294, Sundell:2011:LAC:1989493.1989550}. SALSA extends on the idea of
chunk-based data structures by using chunks also for efficient stealing.